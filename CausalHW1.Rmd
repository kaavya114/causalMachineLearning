---
date: "01/24/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# CS7290 Causal Modeling in Machine Learning: Homework 1

For this assignment, you get your build a generative model with `bnlearn` and with `pyro`. Check out the [*bnlearn* docs](http://www.bnlearn.com) and the [*pyro* docs](http://pyro.ai) if you have questions about these packages.

## Submission guidelines

Use a Jupyter notebook and/or R Markdown file to combine code and text answers.  Compile your solution to a static PDF document(s).  Submit both the compiled PDF and source files.  The TA's will recompile your solutions, and a failing grade will be assigned if the document fails to recompile due to bugs in the code.  If you use [Google Collab](https://colab.research.google.com/notebook), send the link as well as downloaded PDF and source files.

## Background

Recall the survey data discussed in the lecture.

* **Age (A):** It is recorded as *young* (**young**) for individuals below 30 years, *adult* (**adult**) for individuals between 30 and 60 years old, and *old* (**old**) for people older than 60.
* **Sex (S):** The biological sex of individual, recorded as *male* (**M**) or *female* (**F**).
* **Education (E):** The highest level of education or training completed by the individual, recorded either *high school* (**high**) or *university degree* (**uni**).
* **Occupation (O):** It is recorded as an *employee* (**emp**) or a *self employed* (**self**) worker.
* **Residence (R):** The size of the city the individual lives in, recorded as *small* (**small**) or *big* (**big**).
* **Travel (T):** The means of transport favoured by the individual, recorded as *car* (**car**), *train* (**train**) or *other* (**other**)

Travel is the *target* of the survey, the quantity of interest whose behavior is under investigation.

We use the following directed acyclic graph (DAG) as our basis for building a model of the process that generated this data.


## 1 Building a DAG (4 points)

A DAG maps to a factorization of the joint distribution (e.g., $P(A, B, C) == P(A)P(B|A)P(C|B)$).  In *bnlearn*, you can use the function `modelstring(dag)` to convert a DAG into a string representation of a factorization of the joint probability distribution. We can go from a string representation to a DAG using the function `model2network(string)`.

(a) Write out the factorization of the joint distribution implied by the DAG using mathematical notation

    P(A,S,E,O,R,T) = P(A)P(S)P(E|A,S)P(O|E)P(R|E)P(T|O,R)
    
(b) Rewrite the above factorization in *bnlearn*'s string representation.

    [A][S][E|A:S][O|E][R|E][T|O:R]
    
(c) Use this to create a DAG in *bnlearn*.
```{r}
library(bnlearn)
dag <-model2network("[A][S][E|A:S][O|E][R|E][T|O:R]")
print(dag)
```

(d) Print the class of the DAG object.
```{r}
class(dag)
```

(e) Use `graphviz.plot` to plot the DAG.
```{r}
graphviz.plot(dag)
```


## 2 Experimenting with graph utilities (6 points)

(a) Extract and print the nodes and arcs of the DAG you created in previous questions.
```{r}
nodes(dag)
```
```{r}
arcs(dag)
```

(b) Extract and print the parents and the children of each node using `parents` and `children` functions.
```{r}
nodes_dag <- nodes(dag)
for(i in nodes_dag)
{
  cat("node :", i, " ")
  cat("parents :", parents(dag, i), " ")
  cat("children :", children(dag, i), "\n")
}
```

(c) Use the `mb` function to extract the Markov blanket of A, E, and T.
```{r}
mb(dag, "A")
```
```{r}
mb(dag, "E")
```
```{r}
mb(dag, "T")
```

(d) Describe, in terms of the joint probability distribution and NOT in terms of the DAG the definition of a Markov blanket.

P(A | MB(A), B) = P(A | MB(A))

Given the nodes in the Markov Blanket of A, A is conditionally independent of the other nodes in the network.

(e) How do you identify the Markov blanket from the DAG?

Markov Blanket of node i is the set of parents, children and co-parents of node i

## 3 Conditional probability distribution (CPD) parameter estimation (4 points)

Bayesian network = DAG + CPD with specified parameters

(a) Fit the parameters of the DAG from the data stored in survey2.txt using Bayesian estimation, and save the result into an object of class bn.fit.  
```{r}
survey <- read.table("~/Desktop/Causal/bnlearn_trial/survey2.txt", header = TRUE)
bn.surv <- bn.fit(dag, data = survey, method = "bayes")
print(bn.surv)
```

(b) Play with the Bayesian prior parameter **iss** and report the changes in the parameters learned from Bayesian network. Explain the changes.
```{r}
bn.surv1 <- bn.fit(dag, data = survey, method = "bayes", iss = 10)
print(bn.surv1)
```
```{r}
bn.surv2 <- bn.fit(dag, data = survey, method = "bayes", iss = 1000)
print(bn.surv2)
```

The iss parameter is the imaginary sample size used by the bayes method to estimate the conditional probability tables associated with discrete nodes. It is used to preset prior beliefs when calculating the posterior. When the iss value is high, we observe a difference in the conditional probabilities. This happens because when the data set is larger, the prior has a lesser effect on the posterior.

## 4 Graph manipulation (4 points)

(a) Create a copy of the DAG (e.g. `dag2 <- dag`).  Remove the arc from Education to Occupation, and plot the result with `graphviz.plot`.
```{r}
dag2 <- dag
dag2 <- drop.arc(dag2, 'E', 'O')
graphviz.plot(dag2)
```

(b) Fit the parameters of the modified network. Which local distributions change, and how?
```{r}
bn.surv_mod <- bn.fit(dag2, data = survey, method = "bayes", iss = 10)
print(bn.surv_mod)
```

The distribution of O changes, it is not dependent on E anymore.

## 5 Markov equivalence (12 points)

(a) Compute and plot the PDAG of the DAG for the survey data using the `cpdag` function.  Call this PDAG P1 and the original DAG D1.  How does P1 and D1 compare?  Explain any similarities or differences.

```{r}
d1 <- dag
print(d1)
p1 <- cpdag(bn.surv)
print(p1)
graphviz.plot(p1)
```

P1 and D1 are the same. They both have the same 6 directed edges.

(b) Create a DAG D2 that is the same as D1 except that it has a new arc from Occupation to Residence.  This makes sense because surely somebody's job determines where they live (or is it the other way around?).  Note that this is a fine example of applying domain knowledge about the data generative process in causal model development. Plot the result with `graphviz.plot`.
```{r}
d2 <- set.arc(d1, 'O', 'R')
graphviz.plot(d2)
```

(c) Now recompute a PDAG P2 from D2.  What, if anything, is different between P1 and P2 and what explains these differences or lack of differences?
```{r}
p2 <- cpdag(d2)
graphviz.plot(p2)
```

There is an undirected edge between O and R in P2, whereas all the edges in P1 are directed. 
This happens because in D2, the edge from O to R on reversal will result in the new DAG being in the same Markov Equivalence class as D2. However, reversing any edge in D1 will result in the new graph being in a different Markov Equivalence class.

(d) Create a third DAG D3 that is different from the second DAG (with the O->R edge) but is in the same Markov equivalence class. Do this by reasoning about P2 -- in other words look at P2 and create another DAG D3, such that `cpdag(D3)` will also produce P2.  Plot D3.
```{r}
d3 <- set.arc(d1, 'R', 'O')
p3 <- cpdag(d3)
graphviz.plot(d3)
graphviz.plot(p3)

```

(e) Calculate the log-likelihood of the data given D2 and the log-likelihood of the data given D3.  These values should be the same, explain why.  You can use the `score` function with the argument `type = 'loglik`, or you can simply se the `logLik` function, which is just a wrapper for `score`.  You don't need to provide paramter values for the CPDs of the DAG, `score` will estimate them for you.
```{r}
score(d2, survey, type = 'loglik')
score(d3, survey, type = 'loglik')
```

Since the edges from O to R and R to O produce the same PDAG and their respective DAGs are part of the same Markov Equivalence class, the log-likelihood of D2, D3 given the data is the same.
